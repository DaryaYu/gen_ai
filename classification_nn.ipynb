{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sns.load_dataset('titanic')\n",
    "print(data.shape)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 15 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   survived     891 non-null    int64   \n",
      " 1   pclass       891 non-null    int64   \n",
      " 2   sex          891 non-null    object  \n",
      " 3   age          714 non-null    float64 \n",
      " 4   sibsp        891 non-null    int64   \n",
      " 5   parch        891 non-null    int64   \n",
      " 6   fare         891 non-null    float64 \n",
      " 7   embarked     889 non-null    object  \n",
      " 8   class        891 non-null    category\n",
      " 9   who          891 non-null    object  \n",
      " 10  adult_male   891 non-null    bool    \n",
      " 11  deck         203 non-null    category\n",
      " 12  embark_town  889 non-null    object  \n",
      " 13  alive        891 non-null    object  \n",
      " 14  alone        891 non-null    bool    \n",
      "dtypes: bool(2), category(2), float64(2), int64(4), object(5)\n",
      "memory usage: 80.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         survived      pclass         age       sibsp       parch        fare\n",
       "count  891.000000  891.000000  714.000000  891.000000  891.000000  891.000000\n",
       "mean     0.383838    2.308642   29.699118    0.523008    0.381594   32.204208\n",
       "std      0.486592    0.836071   14.526497    1.102743    0.806057   49.693429\n",
       "min      0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    2.000000   20.125000    0.000000    0.000000    7.910400\n",
       "50%      0.000000    3.000000   28.000000    0.000000    0.000000   14.454200\n",
       "75%      1.000000    3.000000   38.000000    1.000000    0.000000   31.000000\n",
       "max      1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column 'survived' looks like our target. \n",
    "Column 'alive' looks like the duplication of 'survived', so we have to remove it from the dataset.\n",
    "Columns 'who' and 'adult_male' combine columns 'age' and 'sex', so we'll remove it.\n",
    "Column 'pclass' and 'class' are also duplicates, we'll drop 'class'.\n",
    "The same is with columns 'embarked' and 'embark_town', we'll leave only 'embarked'.\n",
    "Also, we'll remove column 'alone', because it sums up columns 'sibsp' and 'parch', that we'll use as features.\n",
    "There are some categorical features in the dataset, that we will have to preprocess with one-hot encoding.\n",
    "Also, columns 'age', 'deck' and 'embarked' contain missing values, that we will have to fill in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['alive', 'who', 'adult_male', 'class', 'embark_town', 'alone'], axis=1, inplace=True)\n",
    "\n",
    "data.age.fillna(data.age.mean(), inplace=True)\n",
    "\n",
    "data['gender_female'] = data.sex == 'female'\n",
    "data.drop('sex', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = data.select_dtypes(include=['category', 'object', 'string']).columns\n",
    "for cat in categorical_columns:\n",
    "    data[cat] = data[cat].astype(str).replace('nan', 'unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('survived', axis=1), data['survived'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse=False, drop=None, dtype=int)\\\n",
    "    .fit(X_train[categorical_columns])\n",
    "X_train = np.concatenate((\n",
    "    X_train.drop(categorical_columns, axis=1).values,\n",
    "    ohe.transform(X_train[categorical_columns])\n",
    "), axis=1)\n",
    "X_test = np.concatenate((\n",
    "    X_test.drop(categorical_columns, axis=1).values,\n",
    "    ohe.transform(X_test[categorical_columns])\n",
    "), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler().fit(X_train)\n",
    "X_train_scaled = ss.transform(X_train)\n",
    "X_test_scaled = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf = Sequential([\n",
    "    Input(shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "18/18 [==============================] - 1s 20ms/step - loss: 0.5713 - accuracy: 0.7065 - val_loss: 0.4842 - val_accuracy: 0.8042\n",
      "Epoch 2/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4556 - accuracy: 0.8067 - val_loss: 0.4597 - val_accuracy: 0.8112\n",
      "Epoch 3/20\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.8225 - val_loss: 0.4497 - val_accuracy: 0.8392\n",
      "Epoch 4/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3979 - accuracy: 0.8348 - val_loss: 0.4691 - val_accuracy: 0.8042\n",
      "Epoch 5/20\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.3984 - accuracy: 0.8330 - val_loss: 0.4678 - val_accuracy: 0.8182\n",
      "Epoch 6/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3940 - accuracy: 0.8383 - val_loss: 0.4772 - val_accuracy: 0.8112\n",
      "Epoch 7/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3705 - accuracy: 0.8541 - val_loss: 0.4761 - val_accuracy: 0.8322\n",
      "Epoch 8/20\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.3742 - accuracy: 0.8489 - val_loss: 0.4850 - val_accuracy: 0.8252\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4013 - accuracy: 0.8427\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.8045\n",
      "Train accuracy:  0.8427, test accuracy:  0.8045\n"
     ]
    }
   ],
   "source": [
    "# Let's see model results using 'Adam' optimizer\n",
    "model_tf.compile(\n",
    "    optimizer=Adam(learning_rate=0.01),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model_tf.fit(\n",
    "    X_train_scaled, y_train, \n",
    "    epochs=20, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2, \n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "print(f'Train accuracy: {model_tf.evaluate(X_train_scaled, y_train)[1]: .4f}, test accuracy: {model_tf.evaluate(X_test_scaled, y_test)[1]: .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "18/18 [==============================] - 1s 17ms/step - loss: 0.3891 - accuracy: 0.8418 - val_loss: 0.4497 - val_accuracy: 0.8392\n",
      "Epoch 2/20\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3890 - accuracy: 0.8436 - val_loss: 0.4497 - val_accuracy: 0.8392\n",
      "Epoch 3/20\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.3889 - accuracy: 0.8436 - val_loss: 0.4497 - val_accuracy: 0.8392\n",
      "Epoch 4/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3888 - accuracy: 0.8418 - val_loss: 0.4497 - val_accuracy: 0.8392\n",
      "Epoch 5/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3887 - accuracy: 0.8418 - val_loss: 0.4497 - val_accuracy: 0.8392\n",
      "Epoch 6/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.3886 - accuracy: 0.8436 - val_loss: 0.4498 - val_accuracy: 0.8392\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4012 - accuracy: 0.8427\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4575 - accuracy: 0.8045\n",
      "Train accuracy:  0.8427, test accuracy:  0.8045\n"
     ]
    }
   ],
   "source": [
    "# Let's see model results using 'SGD' optimizer\n",
    "model_tf.compile(\n",
    "    optimizer=SGD(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model_tf.fit(\n",
    "    X_train_scaled, y_train, \n",
    "    epochs=20, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "print(f'Train accuracy: {model_tf.evaluate(X_train_scaled, y_train)[1]: .4f}, test accuracy: {model_tf.evaluate(X_test_scaled, y_test)[1]: .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "18/18 [==============================] - 1s 19ms/step - loss: 0.9885 - accuracy: 0.7557 - val_loss: 0.6915 - val_accuracy: 0.8112\n",
      "Epoch 2/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.6357 - accuracy: 0.8137 - val_loss: 0.5652 - val_accuracy: 0.8182\n",
      "Epoch 3/20\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5620 - accuracy: 0.8102 - val_loss: 0.5350 - val_accuracy: 0.8322\n",
      "Epoch 4/20\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5349 - accuracy: 0.8155 - val_loss: 0.5232 - val_accuracy: 0.8112\n",
      "Epoch 5/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5169 - accuracy: 0.8243 - val_loss: 0.5068 - val_accuracy: 0.8182\n",
      "Epoch 6/20\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4997 - accuracy: 0.8243 - val_loss: 0.4879 - val_accuracy: 0.8252\n",
      "Epoch 7/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4974 - accuracy: 0.8243 - val_loss: 0.4929 - val_accuracy: 0.8322\n",
      "Epoch 8/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5002 - accuracy: 0.8207 - val_loss: 0.4972 - val_accuracy: 0.8042\n",
      "Epoch 9/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4992 - accuracy: 0.8190 - val_loss: 0.4967 - val_accuracy: 0.8112\n",
      "Epoch 10/20\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5000 - accuracy: 0.8120 - val_loss: 0.4970 - val_accuracy: 0.8182\n",
      "Epoch 11/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4964 - accuracy: 0.8243 - val_loss: 0.4962 - val_accuracy: 0.8182\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.8371\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.8101\n",
      "Train accuracy:  0.8371, test accuracy:  0.8101\n"
     ]
    }
   ],
   "source": [
    "# Let's add to the model l2 regularization\n",
    "model_tf = Sequential([\n",
    "    Input(shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dense(32, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dense(1, activation='sigmoid', kernel_regularizer=l2(0.01))\n",
    "])\n",
    "model_tf.compile(\n",
    "    optimizer=Adam(learning_rate=0.01),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model_tf.fit(\n",
    "    X_train_scaled, y_train, \n",
    "    epochs=20, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "print(f'Train accuracy: {model_tf.evaluate(X_train_scaled, y_train)[1]: .4f}, test accuracy: {model_tf.evaluate(X_test_scaled, y_test)[1]: .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "18/18 [==============================] - 1s 20ms/step - loss: 1.0722 - accuracy: 0.7522 - val_loss: 0.7783 - val_accuracy: 0.8182\n",
      "Epoch 2/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7072 - accuracy: 0.8067 - val_loss: 0.6202 - val_accuracy: 0.8252\n",
      "Epoch 3/20\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.6202 - accuracy: 0.8067 - val_loss: 0.5627 - val_accuracy: 0.8112\n",
      "Epoch 4/20\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5631 - accuracy: 0.8032 - val_loss: 0.5269 - val_accuracy: 0.8182\n",
      "Epoch 5/20\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5386 - accuracy: 0.8137 - val_loss: 0.5198 - val_accuracy: 0.8042\n",
      "Epoch 6/20\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5417 - accuracy: 0.8102 - val_loss: 0.5245 - val_accuracy: 0.8042\n",
      "Epoch 7/20\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.5436 - accuracy: 0.8155 - val_loss: 0.5168 - val_accuracy: 0.8042\n",
      "Epoch 8/20\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5229 - accuracy: 0.8067 - val_loss: 0.5079 - val_accuracy: 0.8042\n",
      "Epoch 9/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5302 - accuracy: 0.8032 - val_loss: 0.4996 - val_accuracy: 0.8182\n",
      "Epoch 10/20\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5137 - accuracy: 0.8155 - val_loss: 0.5012 - val_accuracy: 0.8112\n",
      "Epoch 11/20\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5249 - accuracy: 0.8155 - val_loss: 0.5099 - val_accuracy: 0.8112\n",
      "Epoch 12/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5309 - accuracy: 0.8137 - val_loss: 0.5199 - val_accuracy: 0.8112\n",
      "Epoch 13/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5454 - accuracy: 0.8032 - val_loss: 0.5189 - val_accuracy: 0.8182\n",
      "Epoch 14/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5296 - accuracy: 0.8137 - val_loss: 0.5180 - val_accuracy: 0.8182\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.8258\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4882 - accuracy: 0.8324\n",
      "Train accuracy:  0.8258, test accuracy:  0.8324\n"
     ]
    }
   ],
   "source": [
    "# Let's also add the Dropout to the model\n",
    "model_tf = Sequential([\n",
    "    Input(shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid', kernel_regularizer=l2(0.01))\n",
    "])\n",
    "model_tf.compile(\n",
    "    optimizer=Adam(learning_rate=0.01),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model_tf.fit(\n",
    "    X_train_scaled, y_train, \n",
    "    epochs=20, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "print(f'Train accuracy: {model_tf.evaluate(X_train_scaled, y_train)[1]: .4f}, test accuracy: {model_tf.evaluate(X_test_scaled, y_test)[1]: .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "18/18 [==============================] - 1s 18ms/step - loss: 0.5746 - accuracy: 0.7083 - val_loss: 0.4488 - val_accuracy: 0.8042\n",
      "Epoch 2/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4805 - accuracy: 0.7891 - val_loss: 0.4417 - val_accuracy: 0.8042\n",
      "Epoch 3/20\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4812 - accuracy: 0.8102 - val_loss: 0.4410 - val_accuracy: 0.8112\n",
      "Epoch 4/20\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4597 - accuracy: 0.8014 - val_loss: 0.4571 - val_accuracy: 0.8182\n",
      "Epoch 5/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4377 - accuracy: 0.8190 - val_loss: 0.4584 - val_accuracy: 0.8252\n",
      "Epoch 6/20\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4187 - accuracy: 0.8207 - val_loss: 0.4517 - val_accuracy: 0.8322\n",
      "Epoch 7/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4308 - accuracy: 0.8190 - val_loss: 0.4588 - val_accuracy: 0.8182\n",
      "Epoch 8/20\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4108 - accuracy: 0.8313 - val_loss: 0.4779 - val_accuracy: 0.8112\n",
      "23/23 [==============================] - 0s 2ms/step - loss: 0.4112 - accuracy: 0.8272\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.8045\n",
      "Train accuracy:  0.8272, test accuracy:  0.8045\n"
     ]
    }
   ],
   "source": [
    "# Let's remove l2 regularization, but leave Dropout\n",
    "model_tf = Sequential([\n",
    "    Input(shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_tf.compile(\n",
    "    optimizer=Adam(learning_rate=0.01),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model_tf.fit(\n",
    "    X_train_scaled, y_train, \n",
    "    epochs=20, \n",
    "    batch_size=32, \n",
    "    validation_split=0.2,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "print(f'Train accuracy: {model_tf.evaluate(X_train_scaled, y_train)[1]: .4f}, test accuracy: {model_tf.evaluate(X_test_scaled, y_test)[1]: .4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, X):\n",
    "        return self.layers(X)\n",
    "\n",
    "model = MLP(input_dim=X_train_scaled.shape[1])\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss:  0.6831, Test loss:  0.6346\n",
      "Epoch 2, Train loss:  0.6430, Test loss:  0.5946\n",
      "Epoch 3, Train loss:  0.6062, Test loss:  0.5542\n",
      "Epoch 4, Train loss:  0.5687, Test loss:  0.5145\n",
      "Epoch 5, Train loss:  0.5309, Test loss:  0.4778\n",
      "Epoch 6, Train loss:  0.4946, Test loss:  0.4472\n",
      "Epoch 7, Train loss:  0.4616, Test loss:  0.4284\n",
      "Epoch 8, Train loss:  0.4358, Test loss:  0.4282\n",
      "Epoch 9, Train loss:  0.4229, Test loss:  0.4445\n",
      "Epoch 10, Train loss:  0.4219, Test loss:  0.4672\n",
      "Epoch 11, Train loss:  0.4255, Test loss:  0.4834\n",
      "Epoch 12, Train loss:  0.4269, Test loss:  0.4873\n",
      "Epoch 13, Train loss:  0.4236, Test loss:  0.4807\n",
      "Epoch 14, Train loss:  0.4175, Test loss:  0.4688\n",
      "Epoch 15, Train loss:  0.4105, Test loss:  0.4563\n",
      "Epoch 16, Train loss:  0.4032, Test loss:  0.4457\n",
      "Epoch 17, Train loss:  0.3951, Test loss:  0.4385\n",
      "Epoch 18, Train loss:  0.3879, Test loss:  0.4345\n",
      "Epoch 19, Train loss:  0.3830, Test loss:  0.4322\n",
      "Epoch 20, Train loss:  0.3807, Test loss:  0.4301\n",
      "Train accuracy:  0.8497, Test accuracy:  0.8101\n"
     ]
    }
   ],
   "source": [
    "# Let's experiment with Adam optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test_tensor)\n",
    "        test_loss = criterion(test_outputs, y_test_tensor)\n",
    "        \n",
    "    print(f'Epoch {epoch+1}, Train loss: {loss.item(): .4f}, Test loss: {test_loss.item(): .4f}')\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_train_pred = (model(X_train_tensor)>=0.5).float()\n",
    "    train_accuracy = (y_train_pred == y_train_tensor).float().mean()\n",
    "    y_test_pred = (model(X_test_tensor)>=0.5).float()\n",
    "    test_accuracy = (y_test_pred == y_test_tensor).float().mean()\n",
    "print(f'Train accuracy: {train_accuracy: .4f}, Test accuracy: {test_accuracy: .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss:  0.3795, Test loss:  0.4300\n",
      "Epoch 2, Train loss:  0.3795, Test loss:  0.4299\n",
      "Epoch 3, Train loss:  0.3794, Test loss:  0.4298\n",
      "Epoch 4, Train loss:  0.3794, Test loss:  0.4297\n",
      "Epoch 5, Train loss:  0.3793, Test loss:  0.4296\n",
      "Epoch 6, Train loss:  0.3793, Test loss:  0.4295\n",
      "Epoch 7, Train loss:  0.3792, Test loss:  0.4295\n",
      "Epoch 8, Train loss:  0.3792, Test loss:  0.4294\n",
      "Epoch 9, Train loss:  0.3791, Test loss:  0.4293\n",
      "Epoch 10, Train loss:  0.3791, Test loss:  0.4292\n",
      "Epoch 11, Train loss:  0.3790, Test loss:  0.4291\n",
      "Epoch 12, Train loss:  0.3790, Test loss:  0.4291\n",
      "Epoch 13, Train loss:  0.3789, Test loss:  0.4290\n",
      "Epoch 14, Train loss:  0.3789, Test loss:  0.4289\n",
      "Epoch 15, Train loss:  0.3789, Test loss:  0.4289\n",
      "Epoch 16, Train loss:  0.3788, Test loss:  0.4288\n",
      "Epoch 17, Train loss:  0.3788, Test loss:  0.4287\n",
      "Epoch 18, Train loss:  0.3787, Test loss:  0.4287\n",
      "Epoch 19, Train loss:  0.3787, Test loss:  0.4286\n",
      "Epoch 20, Train loss:  0.3786, Test loss:  0.4286\n",
      "Train accuracy:  0.8497, Test accuracy:  0.8212\n"
     ]
    }
   ],
   "source": [
    "# Let's experiment with SGD optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test_tensor)\n",
    "        test_loss = criterion(test_outputs, y_test_tensor)\n",
    "        \n",
    "    print(f'Epoch {epoch+1}, Train loss: {loss.item(): .4f}, Test loss: {test_loss.item(): .4f}')\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_train_pred = (model(X_train_tensor)>0.5).float()\n",
    "    train_accuracy = (y_train_pred == y_train_tensor).float().mean()\n",
    "    y_test_pred = (model(X_test_tensor)>0.5).float()\n",
    "    test_accuracy = (y_test_pred == y_test_tensor).float().mean()\n",
    "print(f'Train accuracy: {train_accuracy: .4f}, Test accuracy: {test_accuracy: .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss:  0.3786, Test loss:  0.4136\n",
      "Epoch 2, Train loss:  0.3759, Test loss:  0.4132\n",
      "Epoch 3, Train loss:  0.3737, Test loss:  0.4145\n",
      "Epoch 4, Train loss:  0.3729, Test loss:  0.4112\n",
      "Epoch 5, Train loss:  0.3721, Test loss:  0.4073\n",
      "Epoch 6, Train loss:  0.3715, Test loss:  0.4042\n",
      "Epoch 7, Train loss:  0.3709, Test loss:  0.4030\n",
      "Epoch 8, Train loss:  0.3699, Test loss:  0.4027\n",
      "Epoch 9, Train loss:  0.3689, Test loss:  0.4016\n",
      "Epoch 10, Train loss:  0.3677, Test loss:  0.3998\n",
      "Epoch 11, Train loss:  0.3662, Test loss:  0.3995\n",
      "Epoch 12, Train loss:  0.3646, Test loss:  0.4007\n",
      "Epoch 13, Train loss:  0.3632, Test loss:  0.4017\n",
      "Epoch 14, Train loss:  0.3620, Test loss:  0.4008\n",
      "Epoch 15, Train loss:  0.3610, Test loss:  0.3988\n",
      "Epoch 16, Train loss:  0.3600, Test loss:  0.3981\n",
      "Epoch 17, Train loss:  0.3588, Test loss:  0.3997\n",
      "Epoch 18, Train loss:  0.3576, Test loss:  0.4023\n",
      "Epoch 19, Train loss:  0.3565, Test loss:  0.4019\n",
      "Epoch 20, Train loss:  0.3555, Test loss:  0.4005\n",
      "Train accuracy:  0.8596, Test accuracy:  0.8212\n"
     ]
    }
   ],
   "source": [
    "#Let's return optimization Adam and add l2 regularization\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.01)\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test_tensor)\n",
    "        test_loss = criterion(test_outputs, y_test_tensor)\n",
    "        \n",
    "    print(f'Epoch {epoch+1}, Train loss: {loss.item(): .4f}, Test loss: {test_loss.item(): .4f}')\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_train_pred = (model(X_train_tensor)>=0.5).float()\n",
    "    train_accuracy = (y_train_pred == y_train_tensor).float().mean()\n",
    "    y_test_pred = (model(X_test_tensor)>=0.5).float()\n",
    "    test_accuracy = (y_test_pred == y_test_tensor).float().mean()\n",
    "print(f'Train accuracy: {train_accuracy: .4f}, Test accuracy: {test_accuracy: .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's add Dropout layer to the model class\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, X):\n",
    "        return self.layers(X)\n",
    "\n",
    "model = MLP(input_dim=X_train_scaled.shape[1])\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss:  0.7104, Test loss:  0.6779\n",
      "Epoch 2, Train loss:  0.6792, Test loss:  0.6473\n",
      "Epoch 3, Train loss:  0.6562, Test loss:  0.6113\n",
      "Epoch 4, Train loss:  0.6261, Test loss:  0.5699\n",
      "Epoch 5, Train loss:  0.5957, Test loss:  0.5248\n",
      "Epoch 6, Train loss:  0.5593, Test loss:  0.4818\n",
      "Epoch 7, Train loss:  0.5096, Test loss:  0.4461\n",
      "Epoch 8, Train loss:  0.5065, Test loss:  0.4232\n",
      "Epoch 9, Train loss:  0.4622, Test loss:  0.4142\n",
      "Epoch 10, Train loss:  0.4735, Test loss:  0.4189\n",
      "Epoch 11, Train loss:  0.4780, Test loss:  0.4358\n",
      "Epoch 12, Train loss:  0.4502, Test loss:  0.4562\n",
      "Epoch 13, Train loss:  0.4700, Test loss:  0.4735\n",
      "Epoch 14, Train loss:  0.4570, Test loss:  0.4858\n",
      "Epoch 15, Train loss:  0.4552, Test loss:  0.4847\n",
      "Epoch 16, Train loss:  0.4699, Test loss:  0.4730\n",
      "Epoch 17, Train loss:  0.4663, Test loss:  0.4597\n",
      "Epoch 18, Train loss:  0.4285, Test loss:  0.4485\n",
      "Epoch 19, Train loss:  0.4353, Test loss:  0.4402\n",
      "Epoch 20, Train loss:  0.4325, Test loss:  0.4332\n",
      "Train accuracy:  0.8315, Test accuracy:  0.7821\n"
     ]
    }
   ],
   "source": [
    "#Let's use Adam optimizer again\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test_tensor)\n",
    "        test_loss = criterion(test_outputs, y_test_tensor)\n",
    "        \n",
    "    print(f'Epoch {epoch+1}, Train loss: {loss.item(): .4f}, Test loss: {test_loss.item(): .4f}')\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_train_pred = (model(X_train_tensor)>=0.5).float()\n",
    "    train_accuracy = (y_train_pred == y_train_tensor).float().mean()\n",
    "    y_test_pred = (model(X_test_tensor)>=0.5).float()\n",
    "    test_accuracy = (y_test_pred == y_test_tensor).float().mean()\n",
    "print(f'Train accuracy: {train_accuracy: .4f}, Test accuracy: {test_accuracy: .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train loss:  0.4250, Test loss:  0.4387\n",
      "Epoch 2, Train loss:  0.4341, Test loss:  0.4359\n",
      "Epoch 3, Train loss:  0.4199, Test loss:  0.4274\n",
      "Epoch 4, Train loss:  0.4097, Test loss:  0.4186\n",
      "Epoch 5, Train loss:  0.4026, Test loss:  0.4128\n",
      "Epoch 6, Train loss:  0.4045, Test loss:  0.4105\n",
      "Epoch 7, Train loss:  0.4024, Test loss:  0.4109\n",
      "Epoch 8, Train loss:  0.4096, Test loss:  0.4137\n",
      "Epoch 9, Train loss:  0.4236, Test loss:  0.4173\n",
      "Epoch 10, Train loss:  0.3994, Test loss:  0.4194\n",
      "Epoch 11, Train loss:  0.3948, Test loss:  0.4188\n",
      "Epoch 12, Train loss:  0.3949, Test loss:  0.4176\n",
      "Epoch 13, Train loss:  0.4012, Test loss:  0.4154\n",
      "Epoch 14, Train loss:  0.3927, Test loss:  0.4138\n",
      "Epoch 15, Train loss:  0.3965, Test loss:  0.4124\n",
      "Epoch 16, Train loss:  0.3958, Test loss:  0.4109\n",
      "Epoch 17, Train loss:  0.4090, Test loss:  0.4095\n",
      "Epoch 18, Train loss:  0.3927, Test loss:  0.4077\n",
      "Epoch 19, Train loss:  0.3932, Test loss:  0.4056\n",
      "Epoch 20, Train loss:  0.4012, Test loss:  0.4038\n",
      "Train accuracy:  0.8525, Test accuracy:  0.8268\n"
     ]
    }
   ],
   "source": [
    "#Let's add l2 regularization to the last version\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01, weight_decay=0.01)\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test_tensor)\n",
    "        test_loss = criterion(test_outputs, y_test_tensor)\n",
    "        \n",
    "    print(f'Epoch {epoch+1}, Train loss: {loss.item(): .4f}, Test loss: {test_loss.item(): .4f}')\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_train_pred = (model(X_train_tensor)>=0.5).float()\n",
    "    train_accuracy = (y_train_pred == y_train_tensor).float().mean()\n",
    "    y_test_pred = (model(X_test_tensor)>=0.5).float()\n",
    "    test_accuracy = (y_test_pred == y_test_tensor).float().mean()\n",
    "print(f'Train accuracy: {train_accuracy: .4f}, Test accuracy: {test_accuracy: .4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the homework I trained binary classification models using Temsorflow and Pytorch.\n",
    "I conducted following exeperiments for both implementations:\n",
    "1. Used Adam optimizer.\n",
    "2. Used SGD Optimizer.\n",
    "3. Returned to Adam optimizer and applied l2 regularization.\n",
    "4. Adam + l2, and also added Dropout.\n",
    "5. Adam optimizer + Dropout without l2.\n",
    "\n",
    "In general, without l2 and Dropout, the models did not overfit a lot, so l2 and Dropout just slightly improved the results.\n",
    "Experiments showed that regularization helped to improve results more in tensorflow implementation than in pytorch.\n",
    "\n",
    "Please see below the accuracy results from experiments.\n",
    "The best accuracy on the test set was on tensorflow implementation with Adam optimizer including Dropout and l2 - 0.8324. The train accuracy in that experiment was on 0.66p.p. lower than the test accuracy, because Dropout is applied only on the train set, so the results are more strict during the training. \n",
    "\n",
    "\n",
    "Tensorflow implementation\n",
    "Adam optimizer\n",
    "Train accuracy:  0.8427, test accuracy:  0.8045\n",
    "SGD optimizer\n",
    "Train accuracy:  0.8427, test accuracy:  0.8045\n",
    "Adam + l2 regularization\n",
    "Train accuracy:  0.8371, test accuracy:  0.8101\n",
    "Adam + Dropout\n",
    "Train accuracy:  0.8272, test accuracy:  0.8045\n",
    "Adam + Dropout + l2\n",
    "Train accuracy:  0.8258, test accuracy:  0.8324\n",
    "\n",
    "Pytorch implementation\n",
    "Adam optimizer\n",
    "Train accuracy:  0.8497, test accuracy:  0.8101\n",
    "SGD optimizer\n",
    "Train accuracy:  0.8497, test accuracy:  0.8212\n",
    "Adam + l2 regularization\n",
    "Train accuracy:  0.8596, test accuracy:  0.8212\n",
    "Adam + Dropout\n",
    "Train accuracy:  0.8315, test accuracy:  0.7821\n",
    "Adam + Dropout + l2\n",
    "Train accuracy:  0.8525, test accuracy:  0.8268"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

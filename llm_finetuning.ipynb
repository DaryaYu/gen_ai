{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Qs3jSgdOc-Xw"
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets evaluate --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WSQHqSldYek9"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForLanguageModeling, EarlyStoppingCallback\n",
    "from datasets import load_dataset\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LMOvjilrcsAZ",
    "outputId": "6615e827-ba89-4e2f-efa9-f607264a7559"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset structure: \n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['query', 'response'],\n",
      "        num_rows: 104848\n",
      "    })\n",
      "})\n",
      "Dataset sample: \n",
      "{'query': 'Create a nested loop to print every combination of numbers between 0-9, excluding any combination that contains the number 5. Additionally, exclude any combination that contains a repeating digit. Implement the solution without using any built-in functions or libraries to check for repeating digits.', 'response': 'Here is an example of a nested loop in Python to print every combination of numbers between 0-9, excluding any combination that contains the number 5 or repeating digits:\\n\\n```python\\nfor i in range(10):  # First digit\\n    for j in range(10):  # Second digit\\n        for k in range(10):  # Third digit\\n            # Checking for the conditions\\n            if i != 5 and j != 5 and k != 5 and i != j and i != k and j != k:\\n                print(i, j, k)\\n```\\n\\nThis code will generate and print every combination of three digits between 0-9 that do not contain the number 5 and do not have any repeating digits.'}\n"
     ]
    }
   ],
   "source": [
    "# Text generation task on the dataset with python code\n",
    "\n",
    "output_dir = './gpt2-codefeedback'\n",
    "model_name = 'distilgpt2'\n",
    "dataset_name = 'fxmeng/CodeFeedback-Python105K'\n",
    "\n",
    "dataset = load_dataset(dataset_name)\n",
    "print(f\"Dataset structure: \\n{dataset}\")\n",
    "print(f\"Dataset sample: \\n{dataset['train'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vE6v7kITCpuW",
    "outputId": "c79f6aa7-e7d4-4a13-e162-343063c28aa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['query', 'response'],\n",
      "        num_rows: 9000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['query', 'response'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# The dataset contains only train part, so we'll divide it on two parts: train and test (10% of data) to evaluate the model\n",
    "\n",
    "dataset = dataset['train'].shuffle().select(range(10000)).train_test_split(test_size=0.1)\n",
    "train = dataset['train']\n",
    "test = dataset['test']\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "60e96eec87fb41c3af9c4bcd67e0c12e",
      "060677ecd0aa4f518a507451c02be108",
      "c88e8f35a99c45be8b1a6e01e18853c8",
      "9ba7f439e3dc4330b95c52ca983048ba",
      "619505d74364425ca263fcb1d141ff4c",
      "f8099a6b2fff47c2b0a3fa9f7dfc5b85",
      "d2591f4ac53e4cddbe80930cdb083c3a",
      "6c899eaf1a0b45ea8c7f9dd534d33ae4",
      "eb78059ba87549bf955e5ce1df5d7b55",
      "9de1881abc7541c8b54fc131b3303ff5",
      "7eb2e5e67a674577b85622013071f677",
      "fe0b13c21b104b598cde2a7c6c419923",
      "3ee62e9de2494aa19c492c70d4da345f",
      "098a9c0dac4146e2a57459d86c473cd0",
      "e1f780df61cb4a768e7d872d15c7e275",
      "3cbfb1b7abca4a5ab17210b81cca8c35",
      "1d7cf79a534543a194e4053da3bd30f4",
      "166716e73d0748c49b6110b4fe927011",
      "77ef4b3518d2460c90f8f57a955fc01f",
      "79edd32f00774389b1f0076c73e514bf",
      "59e0c2c0811a43e6b5b774adaa5a9bfc",
      "f850409457a84f16b6e7951a25086607"
     ]
    },
    "id": "Hiq_cUgAcxAj",
    "outputId": "ab7e91df-4080-40bd-ad8a-dffa21af0a3e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e96eec87fb41c3af9c4bcd67e0c12e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/9000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0b13c21b104b598cde2a7c6c419923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We converted {'query': 'Write an algorithm to find the common elements in two arrays. The algorithm should have a time complexity of O(n), where n is the size of the larger array. Additionally, you are not allowed to use any additional data structures or built-in functions for solving the problem.', 'response': '1. Initialize an empty array, commonElements, to store the common elements found in both arrays.\\n2. Iterate through the first array, array1, and create a dictionary (hash map) where the keys are the elements in array1 and the values are boolean flags indicating if the element has been encountered or not. Set all values to False initially.\\n3. Iterate through the second array, array2.\\n    - Check if the current element of array2 exists as a key in the dictionary created in step 2.\\n    - If it does, check if the value associated with the key is False. If it is, set the value to True and add the element to the commonElements array.\\n4. Return the commonElements array.\\n\\nPseudocode:\\n```\\nfunction findCommonElements(array1, array2):\\n    commonElements = []\\n    dictionary = {}\\n    \\n    for element in array1:\\n        dictionary[element] = False\\n    \\n    for element in array2:\\n        if element in dictionary and not dictionary[element]:\\n            dictionary[element] = True\\n            commonElements.append(element)\\n    \\n    return commonElements\\n```\\n\\nTime Complexity: O(n), where n is the size of the larger array. Both iterations through the arrays have a time complexity of O(n).'} to \n",
      " {'input_ids': [2, 18233, 25, 198, 16594, 281, 11862, 284, 1064, 262, 2219, 4847, 287, 734, 26515, 13, 383, 11862, 815, 423, 257, 640, 13357, 286, 440, 7, 77, 828, 810, 299, 318, 262, 2546, 286, 262, 4025, 7177, 13, 12032, 11, 345, 389, 407, 3142, 284, 779, 597, 3224, 1366, 8573, 393, 3170, 12, 259, 5499, 329, 18120, 262, 1917, 13, 198, 2, 23998, 25, 198, 16, 13, 20768, 1096, 281, 6565, 7177, 11, 2219, 36, 3639, 11, 284, 3650, 262, 2219, 4847, 1043, 287, 1111, 26515, 13, 198, 17, 13, 40806, 378, 832, 262, 717, 7177, 11, 7177, 16, 11, 290, 2251, 257, 22155, 357, 17831, 3975, 8, 810, 262, 8251, 389, 262, 4847, 287, 7177, 16, 290, 262, 3815, 389, 25131, 9701, 12739, 611, 262, 5002, 468, 587, 12956, 393, 407, 13, 5345, 477, 3815, 284, 10352, 7317, 13, 198, 18, 13, 40806, 378, 832, 262, 1218, 7177, 11, 7177, 17, 13, 198, 220, 220, 220, 532, 6822, 611, 262, 1459, 5002, 286, 7177, 17, 7160, 355, 257, 1994, 287, 262, 22155, 2727, 287, 2239, 362, 13, 198, 220, 220, 220, 532, 1002, 340, 857, 11, 2198, 611, 262, 1988, 3917, 351, 262, 1994, 318, 10352, 13, 1002, 340, 318, 11, 900, 262, 1988, 284, 6407, 290, 751, 262, 5002, 284, 262, 2219, 36, 3639, 7177, 13, 198, 19, 13, 8229, 262, 2219, 36, 3639, 7177, 13, 198, 198, 47, 325, 463, 420, 1098, 25, 198, 15506, 63, 198, 8818, 1064, 17227, 36, 3639, 7, 18747, 16, 11, 7177, 17, 2599, 198, 220, 220, 220, 2219, 36, 3639, 796, 17635, 198, 220, 220, 220, 22155, 796, 23884, 198, 220, 220, 220, 220, 198, 220, 220, 220, 329, 5002, 287, 7177, 16, 25, 198, 220, 220, 220, 220, 220, 220, 220, 22155, 58, 30854, 60, 796, 10352, 198, 220, 220, 220, 220, 198, 220, 220, 220, 329, 5002, 287, 7177, 17, 25, 198, 220, 220, 220, 220, 220, 220, 220, 611, 5002, 287, 22155, 290, 407, 22155, 58, 30854, 5974, 198, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 22155, 58, 30854, 60, 796, 6407, 198, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 2219, 36, 3639, 13, 33295, 7, 30854, 8, 198, 220, 220, 220, 220, 198, 220, 220, 220, 1441, 2219, 36, 3639, 198, 15506, 63, 198, 198, 7575, 19157, 414, 25, 440, 7, 77, 828, 810, 299, 318, 262, 2546, 286, 262, 4025, 7177, 13, 5747, 34820, 832, 262, 26515, 423, 257, 640, 13357, 286, 440, 7, 77, 737, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [2, 18233, 25, 198, 16594, 281, 11862, 284, 1064, 262, 2219, 4847, 287, 734, 26515, 13, 383, 11862, 815, 423, 257, 640, 13357, 286, 440, 7, 77, 828, 810, 299, 318, 262, 2546, 286, 262, 4025, 7177, 13, 12032, 11, 345, 389, 407, 3142, 284, 779, 597, 3224, 1366, 8573, 393, 3170, 12, 259, 5499, 329, 18120, 262, 1917, 13, 198, 2, 23998, 25, 198, 16, 13, 20768, 1096, 281, 6565, 7177, 11, 2219, 36, 3639, 11, 284, 3650, 262, 2219, 4847, 1043, 287, 1111, 26515, 13, 198, 17, 13, 40806, 378, 832, 262, 717, 7177, 11, 7177, 16, 11, 290, 2251, 257, 22155, 357, 17831, 3975, 8, 810, 262, 8251, 389, 262, 4847, 287, 7177, 16, 290, 262, 3815, 389, 25131, 9701, 12739, 611, 262, 5002, 468, 587, 12956, 393, 407, 13, 5345, 477, 3815, 284, 10352, 7317, 13, 198, 18, 13, 40806, 378, 832, 262, 1218, 7177, 11, 7177, 17, 13, 198, 220, 220, 220, 532, 6822, 611, 262, 1459, 5002, 286, 7177, 17, 7160, 355, 257, 1994, 287, 262, 22155, 2727, 287, 2239, 362, 13, 198, 220, 220, 220, 532, 1002, 340, 857, 11, 2198, 611, 262, 1988, 3917, 351, 262, 1994, 318, 10352, 13, 1002, 340, 318, 11, 900, 262, 1988, 284, 6407, 290, 751, 262, 5002, 284, 262, 2219, 36, 3639, 7177, 13, 198, 19, 13, 8229, 262, 2219, 36, 3639, 7177, 13, 198, 198, 47, 325, 463, 420, 1098, 25, 198, 15506, 63, 198, 8818, 1064, 17227, 36, 3639, 7, 18747, 16, 11, 7177, 17, 2599, 198, 220, 220, 220, 2219, 36, 3639, 796, 17635, 198, 220, 220, 220, 22155, 796, 23884, 198, 220, 220, 220, 220, 198, 220, 220, 220, 329, 5002, 287, 7177, 16, 25, 198, 220, 220, 220, 220, 220, 220, 220, 22155, 58, 30854, 60, 796, 10352, 198, 220, 220, 220, 220, 198, 220, 220, 220, 329, 5002, 287, 7177, 17, 25, 198, 220, 220, 220, 220, 220, 220, 220, 611, 5002, 287, 22155, 290, 407, 22155, 58, 30854, 5974, 198, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 22155, 58, 30854, 60, 796, 6407, 198, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 220, 2219, 36, 3639, 13, 33295, 7, 30854, 8, 198, 220, 220, 220, 220, 198, 220, 220, 220, 1441, 2219, 36, 3639, 198, 15506, 63, 198, 198, 7575, 19157, 414, 25, 440, 7, 77, 828, 810, 299, 318, 262, 2546, 286, 262, 4025, 7177, 13, 5747, 34820, 832, 262, 26515, 423, 257, 640, 13357, 286, 440, 7, 77, 737, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]}\n"
     ]
    }
   ],
   "source": [
    "# Now let's preprocess the data specifically for our task and 'gpt2' model\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def preprocess(example):\n",
    "  tokenized = tokenizer(\n",
    "      f\"# Question:\\n{example['query']}\\n# Answer:\\n{example['response']}\",\n",
    "      truncation=True,\n",
    "      padding='max_length',\n",
    "      max_length=512\n",
    "  )\n",
    "  tokenized['labels'] = tokenized['input_ids'].copy()\n",
    "  return tokenized\n",
    "\n",
    "tokenized_train = train.map(preprocess, remove_columns=train.column_names)\n",
    "tokenized_test = test.map(preprocess, remove_columns=test.column_names)\n",
    "print(f\"We converted {train[0]} to \\n {tokenized_train[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "YOBmcbqXUGSH"
   },
   "outputs": [],
   "source": [
    "# Let's define the model\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    eval_strategy='epoch',\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=5e-5,\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=10,\n",
    "    save_strategy='epoch',\n",
    "    report_to='none',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_loss',\n",
    "    greater_is_better=False,\n",
    "    resume_from_checkpoint=True,\n",
    "    fp16=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "id": "3cdWQsBd-HDm",
    "outputId": "1aea277f-34bb-4225-a16b-619a3b15f2b5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13500' max='13500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13500/13500 25:51, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.794100</td>\n",
       "      <td>1.672330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.687900</td>\n",
       "      <td>1.603865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.353700</td>\n",
       "      <td>1.578177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [500/500 00:15]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 4.85\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the model\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "perplexity = math.exp(eval_results['eval_loss'])\n",
    "print(f\"Perplexity: {perplexity:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4T8w1GOz0uGB",
    "outputId": "ec609fbf-a576-4993-d1bd-8166b392b5fb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./gpt2-codefeedback/tokenizer_config.json',\n",
       " './gpt2-codefeedback/special_tokens_map.json',\n",
       " './gpt2-codefeedback/vocab.json',\n",
       " './gpt2-codefeedback/merges.txt',\n",
       " './gpt2-codefeedback/added_tokens.json',\n",
       " './gpt2-codefeedback/tokenizer.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model and tokenizer\n",
    "\n",
    "trainer.save_model(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NqFA6QTa-HHM"
   },
   "outputs": [],
   "source": [
    "# Let's define the funciton of prediction generation:\n",
    "\n",
    "def generate_response(query):\n",
    "  input_ids = tokenizer.encode(\n",
    "      f\"# Question:\\n{query}\\n# Answer:\\n\",\n",
    "      return_tensors='pt'\n",
    "  ).to(model.device)\n",
    "  output_ids = model.generate(\n",
    "      input_ids,\n",
    "      max_new_tokens=200,\n",
    "      do_sample=True,\n",
    "      temperature=0.2\n",
    "  )\n",
    "  result = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "  return result\n",
    "\n",
    "# The model and tokenizer is already in the memory, so we'll skip a step of its loading. But the dataset was overwritten with its sample, so let's load it again\n",
    "dataset = load_dataset(dataset_name)['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0BIMMFYFcxJ1",
    "outputId": "a0536453-46c3-490f-c551-c24f2d7c7b8d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Question:\n",
      "Design a search engine algorithm that first sorts an array of words in alphabetical order and then conducts a binary search for input word queries. Additionally, the algorithm must also predict the next word in the sequence of a given input sentence using a basic predictive model based on the frequency of word sequences in a previously defined text corpus. \n",
      "\n",
      "words = [ 'hello', 'this', 'is', 'a', 'test' ]\n",
      "# Answer:\n",
      "Here is a Python solution using the `sieve` library in Python:\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "\n",
      "def binary_search(words):\n",
      "    # Create a dictionary to store the words in alphabetical order\n",
      "    words = []\n",
      "    # Iterate through each word in the input sentence\n",
      "    for word in words:\n",
      "        # Check if the word is already in the dictionary\n",
      "        if word.isalpha():\n",
      "              # If it is, add it to the dictionary\n",
      "             word.append(word)\n",
      "                                           \n"
     ]
    }
   ],
   "source": [
    "# Let's test a model on an example:\n",
    "\n",
    "any_index = 111\n",
    "print(generate_response(test[any_index]['query']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yo7I72HjMxyG",
    "outputId": "53222624-f5c4-4818-b15a-3226bbb97001"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python provides many helpful libraries for various tasks. One of them is Random library to work with random numbers, another is scikit-learn (a simple and efficient tool for data mining and data analysis), and datetime for date and time tasks. Following is Python code to solve the problem:\n",
      "\n",
      "```python\n",
      "\n",
      "from sklearn.feature_extraction.text import CountVectorizer\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from collections import Counter\n",
      "import numpy as np\n",
      "\n",
      "class SearchEngine:\n",
      "  def __init__(self, words, corpus):\n",
      "    self.words = sorted(words)\n",
      "    self.corpus = corpus.split(' ')\n",
      "    self.model = self.train_model()\n",
      "\n",
      "  def binary_search(self, target):\n",
      "    low = 0\n",
      "    high = len(self.words) - 1\n",
      "    while low <= high:\n",
      "      mid = (low + high) // 2\n",
      "      if self.words[mid] == target:\n",
      "        return mid\n",
      "      elif self.words[mid] < target:\n",
      "        low = mid + 1\n",
      "      else:\n",
      "        high = mid - 1\n",
      "    return -1\n",
      "\n",
      "  def train_model(self):\n",
      "    self.cv = CountVectorizer(ngram_range=(2, 2))\n",
      "    self.n_grams = self.cv.fit_transform(self.corpus)\n",
      "    self.words_matrix = self.cv.transform(self.corpus)\n",
      "    y = np.array([i+1 for i in range(self.words_matrix.shape[0]-1)] + [0])\n",
      "    model = MultinomialNB()\n",
      "    model.fit(self.words_matrix, y)\n",
      "    return model\n",
      "\n",
      "  def predict(self, text):\n",
      "    prediction = self.model.predict(self.cv.transform([text.split(' ')[-1]]))\n",
      "    prediction_proba = self.model.predict_proba(self.cv.transform([text.split(' ')[-1]]))\n",
      "    return self.corpus[prediction[0]], np.max(prediction_proba)\n",
      "\n",
      "words = [ 'hello', 'this', 'is', 'a', 'test' ]\n",
      "corpus = \"this is a test this is only a test\"\n",
      "searchEngine = SearchEngine(words, corpus)\n",
      "print(searchEngine.binary_search('hello'))\n",
      "\n",
      "predicted_word, proba = searchEngine.predict(\"this is a test this\")\n",
      "print(predicted_word, proba)\n",
      "\n",
      "```\n",
      "\n",
      "In this code, we first define a class SearchEngine. It has three class methods: `binary_search()`, `train_model()`, and `predict()`. We perform a binary search on the sorted words array. For prediction, we train a model on the given corpus (text data) using CountVectorizer to transform the text data into a matrix of token counts, then feed this matrix into a Multinomial Naive Bayes classifier. The prediction process uses the last word in the input text and outputs the highest probable next word in the sequence.\n",
      "\n",
      "This is a simplistic model and may not effectively predict words in more complex or varied text data. Other more sophisticated models such as RNNs (Recurrent Neural Networks) or Transformer models (like Google's BERT) may be a better fit for such tasks.\n"
     ]
    }
   ],
   "source": [
    "# Let's see what is the true response on the test query:\n",
    "\n",
    "print(test[any_index]['response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_CBZRhnIOVY"
   },
   "source": [
    "In the homework I fine-tuned the model, that should generate the response with python code based on the query. For that purpose I used the dataset 'fxmeng/CodeFeedback-Python105K', that consists of queries, asking to write a python code, and responses with mixed text and python code respectively. I applied text generation LLM for that case.\n",
    "\n",
    "Experiment 1. Training on CPU.\n",
    "The main problem I faced with is too long time of the model fine-tunning.\n",
    "In order to fasten the training time and decrease the memory usage I:\n",
    "- changed the model from 'gpt2' to 'distilgpt2';\n",
    "- decreased the train and test sample by ~100 times (from 105K to 1K);\n",
    "- changed some hyperparameters.\n",
    "Anyway, even with simplified inputs, it took the model 5 hours to train.\n",
    "As a result, the loss on evaluation dataset improved from 2.05 to 1.97, the perplexity score is rather ok (7.16), but the testing on the real cases showed, that the model had slightly learned the response structure (including python code structure), had good level of text generation, but did not learn to write python code correctly.\n",
    "\n",
    "Experiment 2. Training on GPU T4.\n",
    "In the 2nd experiment I changed the machine from CPU to GPU T4 and increased the sample size to 10K (10 times compared to the 1st experiment).\n",
    "This time it took 26 min to train the same model.\n",
    "The outputs in the saved notebook are from the 2nd exepriment.\n",
    "The loss on the evaluation dataset improved from 1.67 to 1.58, and the perplexity score improved to 4.85.\n",
    "Updated model generates even better python code structure and syntaxis, but still the code itself is meaningless.\n",
    "\n",
    "So, the further ways to improve the model are:\n",
    "- to experiment with the data preprocessing to focus on the python code,\n",
    "- to increase the size of the model (increase train sample size, model type, hyperparameters)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "060677ecd0aa4f518a507451c02be108": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8099a6b2fff47c2b0a3fa9f7dfc5b85",
      "placeholder": "​",
      "style": "IPY_MODEL_d2591f4ac53e4cddbe80930cdb083c3a",
      "value": "Map: 100%"
     }
    },
    "098a9c0dac4146e2a57459d86c473cd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_77ef4b3518d2460c90f8f57a955fc01f",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_79edd32f00774389b1f0076c73e514bf",
      "value": 1000
     }
    },
    "166716e73d0748c49b6110b4fe927011": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1d7cf79a534543a194e4053da3bd30f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3cbfb1b7abca4a5ab17210b81cca8c35": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3ee62e9de2494aa19c492c70d4da345f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1d7cf79a534543a194e4053da3bd30f4",
      "placeholder": "​",
      "style": "IPY_MODEL_166716e73d0748c49b6110b4fe927011",
      "value": "Map: 100%"
     }
    },
    "59e0c2c0811a43e6b5b774adaa5a9bfc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60e96eec87fb41c3af9c4bcd67e0c12e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_060677ecd0aa4f518a507451c02be108",
       "IPY_MODEL_c88e8f35a99c45be8b1a6e01e18853c8",
       "IPY_MODEL_9ba7f439e3dc4330b95c52ca983048ba"
      ],
      "layout": "IPY_MODEL_619505d74364425ca263fcb1d141ff4c"
     }
    },
    "619505d74364425ca263fcb1d141ff4c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c899eaf1a0b45ea8c7f9dd534d33ae4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77ef4b3518d2460c90f8f57a955fc01f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79edd32f00774389b1f0076c73e514bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7eb2e5e67a674577b85622013071f677": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9ba7f439e3dc4330b95c52ca983048ba": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9de1881abc7541c8b54fc131b3303ff5",
      "placeholder": "​",
      "style": "IPY_MODEL_7eb2e5e67a674577b85622013071f677",
      "value": " 9000/9000 [00:27&lt;00:00, 593.88 examples/s]"
     }
    },
    "9de1881abc7541c8b54fc131b3303ff5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c88e8f35a99c45be8b1a6e01e18853c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c899eaf1a0b45ea8c7f9dd534d33ae4",
      "max": 9000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_eb78059ba87549bf955e5ce1df5d7b55",
      "value": 9000
     }
    },
    "d2591f4ac53e4cddbe80930cdb083c3a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e1f780df61cb4a768e7d872d15c7e275": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_59e0c2c0811a43e6b5b774adaa5a9bfc",
      "placeholder": "​",
      "style": "IPY_MODEL_f850409457a84f16b6e7951a25086607",
      "value": " 1000/1000 [00:01&lt;00:00, 612.54 examples/s]"
     }
    },
    "eb78059ba87549bf955e5ce1df5d7b55": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f8099a6b2fff47c2b0a3fa9f7dfc5b85": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f850409457a84f16b6e7951a25086607": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fe0b13c21b104b598cde2a7c6c419923": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3ee62e9de2494aa19c492c70d4da345f",
       "IPY_MODEL_098a9c0dac4146e2a57459d86c473cd0",
       "IPY_MODEL_e1f780df61cb4a768e7d872d15c7e275"
      ],
      "layout": "IPY_MODEL_3cbfb1b7abca4a5ab17210b81cca8c35"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
